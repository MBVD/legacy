### блочные устройства виртуальные

[Артём] divmapper

Нас будет интересовать две вещи:
1) lvm
2) RAID

#### RAID

Основная задача состоит из трех частей:
Смысл RAID - делаем некое виртуальное блочное устройство состоящее из множества других блочных устройств и цель делания этого виртуального блочного устройства в случае RAID их три:
1) Больше (объем доступного пространства)
2) Быстрее(обеспечивать более быстрый доступ к данным за счет параллелизма обращения к устройствам)
3) Надежность (сохранение данных при отказе одного или нескольких устройств)

Идея такая: для RAID требуется чтобы блочные устройства были одинакового размера и если не будет одинаковы то будут приведены к одинаковому минимальному размеру. 

В Linux есть `dm raid` и `md raid`
`dm raid` - виртуальные рейды в том смысле что они не аппаратные ( обычным образом втыкаете раздел дисков в ваше устройство и потом делаете виртуальный рейд на это всё. По идее доолжно повышать надежность и быстродействие). Есть аппаратные на мат плате
`md raid`  существует системная утилита `md adm` создавать разнообразные рейды и есть что-то там в ФС `/proc/md/md-info` 

RAID (RAID0, RAID1, RAID2, `...`)
0. stripe. У нас есть два жестких диска. На жестком диске у нас есть блоки. И еще один жесткий диск тоже с блоками. Мы вот это вот всё отображаем в вирт жесткий диск. Здесь блоки вирт жесткого диска будут рассыпаны по блокам RAID. Вот это 0,2,4 на одном 1,3,5 на другом и совмещается в вирт жестком диске 0,1,2,3,4,... . Если шина позволяет одновременно запись и чтение, то скорость чтения и записи для программы увеличивается в два раза. Что будет если грохнется этот диск? У нас вообще всё потеряется( не спасёт даже дублирование супер блоков в ФС или разделение на блоков). 
1. У нас есть в норме предполагается два диска ( но может быть юольше). У нас есть два диска и еще может быть третий( третий - это запасной) и четвертый ( виртуальное блочное устройство). Зеркалирование: В первом диске(0,1,2,3) во втором диске(0,1,2,3), третий диск не используется ( он называется шинный диск) и в четвертом диске(0,1,2,3). В идеале вот это устройство оно работает со скоростью одного диска ( не должны потерять производительность, но на практие все ранво немного теряется). Когда вы пишете вы сразу пишете на оба диске, а когда читаете, впринципе вы можете читать с любого диска, поэтому на чтение у вас получается скорость потенциадльно может возрасти. Здесь мы жертвуем объемом в угоду третьему пункту надежности, с быстротой у нас как повезёт. Вот такая стратегия защищает от выхода из строя любого из этих дисков(первого второго и четвертого). Зачем нужен третий? Если первый или второй вышел из строя, у нас есть третий подключенный не рабочий диск, мы потихоньку копируем из живого диска на третий диск и переводим третий диск в рабочее состояние после копирования. Хорошо, что тут не надо останавливать машину. Такой RAID обеспечивает падение одного диска, но не обеспечивает ситуацию с тихой порчей данных. Если у вас два разных диска и вот блок номер 2 повредился и имеет измменное значение к блоку номер 2 в первом диске, то вы это не заметите ( данные тихо повреждаются). Можно, если пожертвовать скоростью чтения с блочных устройств, мы можем, когда читать, можем сравнивать блоки между собой ( дорогая операция - замедляется скорость работы), но вы узнаете что данные повреждены, но ничего сделать не сможете. 
2. RAID2 непонятное явление, там нет блоков. RAID2 защищает от тихого . Он выглядит как RAID0. Данные которые ложатся здесь они изменяются. Изменены они таким образом: вычисляется код Хемминга исправляющей ошибки. Данные получаются длиннее так как туда добавляется код Хемминга, но расположение как RAID0. 
	1. ![[Pasted image 20240928112311.png]]
3. ХЗ
4. Для RAID3 добавляется еще один диск с контрольной суммой, каждый раз когда вы пишете что-то, на RAID3 записывается контрольная сумма. RAID3 имеет больший размер чем RAID1, потому что здесь у нас происходит чередование, но вот здесь мы ( на третьем диске) мы вычисляем контрольные суммы. 0+1mod2 2+3mod3. На каждый блок мы заполняем контрольные суммы в диск, что жрет ресурсы
	 ![[Pasted image 20240928111956.png]]
4.
5. Вот у нас три диска. В отличие от RAID3. В чем преимущество такого расположения перед RAID3: диски изнашиваются одновременно. Недостаток в том, что если мы грохнем один диск, то мы точно не сможем ничего писать до тех пор пока не добавим новый третий. 
	1. ![[Pasted image 20240928112649.png]]
6. Это RAID, обеспечивающий восстановление данных при уничтожении двух жестких дисков. У нас храняется две контрольные суммы, которые тоже распределены вокруг. Дисков становятся 4 и с полосой дополнительно хранится контрольная сумма 0+1+z.
	![[Pasted image 20240928112925.png]]

10. RAID0 и RAID1 совмещены вместе: обеспечивается очень высокая скорость чтения, а с 2записью не очень. 

Разумно пользоваться RAID0, если вам не важна надежность
RAID1 если у вас нет жестких дисков
Дальше если у вас больше трех дисков пользуемся RAID5
Если очень много дисков, то пользуемся RAID6
Файловая система не защищает от тихого повреждения данных, она защищает от тихого повреждения метаданных

#### LVM

Решает задачу увеличения объема, быстрого изменения размера блочного устройства и возможность быстрой смены носителей, на которых находятся данные блочного устройства. Выдергиваем диск и пользуемся этим блочным устройством. 

Вы делаете некое виртуальное блочное устройство. Они включены в volume group, они могут быть разных размеров. И соответсвенно логику у volume решает только первую задачу. Мы берем и говорим что вот этот диапазон в нашем `logical volume` отображен в такой диапазон в блочном устройстве. Скоро будет дохый, значит мы вот здесь закопировали, копируем на начало вот этого диапазаона, новгго диска который мы вставляем, а потом эту стрелку перенаправляем вот туда. таким образом, не меняя логическое блочное устройство, мы меняем его поднаготную кду аоно напрвлено. Эту машинария выполняется `devmap`. 

# Средства межпроцессорного взаимодействия

Вы можете писать файлы, открывать в одном процессе, закрывать другой. Этот способ жизни не рассматривается. Какие средства у нас есть:
1) Для родственных процессов. Здесь имеется виду, что создается разделяемый объект, который родственнен для всех и его помнят. 
	1) Неименованные каналы - `pipe` 
	2) Анонимные отображения на память 
	3) Анонимные семафоры 
	4) Теоретически анонимные очереди сообщений. 
2) Для необязательно родственных процессов. IPC. Их бывает два вида:
	1) SystemV
	2) IPC POSIX
	3) FIFO - делается системным вызовом `mkfifo`
	4) Сюда относится FP_UNIX - системный вызов `socket`
	Что их объединяет? Их ресурсы ___именованные___: у нас есть условный процесс или сервер и он создаёт некоторый именованный объект в ФС. Другие процессы/клиенты подключаются к этому  именованному объекту. Этот сервер предоставляет некий сервис для клиентов, чтобы проводить взаимодействия
3) Для процессов расположенных на разных компьютерах ( по сети )
	1) Системный вызов `socket` - создает возможность общаться по сети. 


### Анонимные средства

Это собственно `mmap MAP_ANONYMOUS` 
В данном случае используем семафоры `phtroad.h` `semaphore.h` 
И pipe

### pipe

У нас есть системный вызов 

```c
int pip(int fds[2])
```
При этом в ядре заводится некий буфер некого фиксированного размера. В таблице открытых файлов заводится запись, которая минует таблицу открытых файлов ядра и ведет к буферу. В ТОФ создается две записи ведущие к буферу. 

```c
fds[0] - "читаем из буфера"
fds[1] - "пишем в буфер"
```

Что происходит с ТОФ когда мы активировали `fork` - она копируется. Появляется копия ТОФ ( ТОФ сына), который направлен ровно к такому же буферу и так два процесса могут взаимодействовать друг с другом. Их может быть и больше. Один процесс может записать (по стрелочке для записи), а другой процесс может это прочитать. Что гарантируется:
1) Записи для одного процесса последовательны. Другой процесс будет читать из буфера так как его и положили (как очередь). Читаются и записываются системными вызовами `read` и `write` и закрывать системным вызовом `close` 

### write

атамарные записи - предполагается что в один буфер может писать несколько процессов сразу - возможна ситуация. Один пишет свой buf1 другой пишет свой buf2, а вот это pipe-пространство. В связи с тем, что у нас есть атамарные записи  у нас соовтествующие буфера делятся на кусочки. 1А, 2А, 3А в буф1 1Б, 2Ь, 3Б в буф2. Все что мы пишем, напишется как есть ( единой частью) в pipe может получиться так: 1А, 1Б, 2А, 3А, 2Б, 3Б. 

### Проблемы переполнения буфера

Предположим, что буфер имеет вот такой размер и мы пытаемся запихать 2Б а оно туда не лезет - часть запишется - либо весь атамарный кусок туда влезает либо не влезает. Во-первых, запишется и не запишется куском, а процесс заблокируется на `write`. Блокируется до тех пор пока другой процесс не прочитает те данные которые не влезли в той части которой мы пытались пихать. Процесс который туда фигачит есть, процесс который читает тоже естт, но про него мы забыли. Следующая фишка связанная с `pipe`, если нет ни одного процесса, который готов читать, то есть все файловые дескрипторы, все fd на чтение и записи из `pipe` закрыты из канала. В этой ситуации, как только мы закрывааем последний fd на чтение из канала, ядро уничтожает buf ассоциированный с первым процессом. Процессу приходят такая штука как `SIGPIPE`, которая его убивает. 

#### Неименованные каналы (Буферы)

1. Буфер пустой,  но файловвы


### Идеология pipe

Рыбки

#### FIFO

```c
mkfifo(char* path)
```

Допустим указалали `/tmp/fish_fifo`
Что дальше вы можете с этим сделать:
1. На одном процессе делаете `open("\tmp\fish_fifo", O_WRONLY)` и это условно программа сервера. 
2. Другой делает `open("\tmp\fish_fifo", O_RDONLY)`. Процессор 

Пример
```c
#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>
#inlucde <sys/wait.h>

"Посчитаем количество c-file в каталоге"
"ls | grep ".c" | wc -l"
"l - количество строк"

int main() {
	// Нам нужны pid для 3 процессов: ls, grep, wc
	pid_t ls_pid = -1, grep_pid = -1, wc_pid = -1;

	// Нам нужно два pipe
	int p_ls_grep[2], p_grep_wc[2];

	// Создаем первый канал
	if (pipe(p_ls_grep) == -1) {
		perror("p_ls_grep");
		return 1;
	}
	ls_pid = fork();
	if (ls_pid == -1) {
		perror("ls_pid");
		return 2;
	}

	// А сын ли мы?
	if (ls_pid == 0) {
		ls_pid = get_pid()
		dup2(p_ls_grep[1], 1);
	}
}
```